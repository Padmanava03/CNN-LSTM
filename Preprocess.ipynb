{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b437012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "from scipy.signal import butter, filtfilt, stft\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be203bb",
   "metadata": {},
   "source": [
    "#### MERGE CODE WITH SESSION ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1dde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_excel_sheets_to_parquet_eeg(excel_file_path, output_parquet_path):\n",
    "    xls = pd.ExcelFile(excel_file_path, engine=\"openpyxl\")\n",
    "    sheet_names = xls.sheet_names\n",
    "\n",
    "    # Read first sheet to get column names\n",
    "    df_ref = pd.read_excel(\n",
    "        excel_file_path,\n",
    "        sheet_name=sheet_names[0],\n",
    "        engine=\"openpyxl\"\n",
    "    )\n",
    "    column_names = df_ref.columns.tolist()\n",
    "\n",
    "    # ---- DEFINE FIXED SCHEMA (CRITICAL) ----\n",
    "    fields = [\n",
    "        pa.field(col, pa.float32()) for col in column_names\n",
    "    ]\n",
    "    fields.append(pa.field(\"session_id\", pa.int32()))\n",
    "    schema = pa.schema(fields)\n",
    "    # --------------------------------------\n",
    "\n",
    "    parquet_writer = None\n",
    "\n",
    "    for sheet_idx, sheet_name in enumerate(sheet_names):\n",
    "        print(f\"Processing sheet {sheet_idx}: {sheet_name}\")\n",
    "\n",
    "        df = pd.read_excel(\n",
    "            excel_file_path,\n",
    "            sheet_name=sheet_name,\n",
    "            header=0 if sheet_idx == 0 else None,\n",
    "            engine=\"openpyxl\"\n",
    "        )\n",
    "\n",
    "        if df.shape[1] != len(column_names):\n",
    "            print(f\"Skipping {sheet_name}: column mismatch\")\n",
    "            continue\n",
    "\n",
    "        df.columns = column_names\n",
    "\n",
    "        # Force numeric EEG\n",
    "        df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Enforce dtypes explicitly\n",
    "        df = df.astype({col: \"float32\" for col in column_names})\n",
    "        df[\"session_id\"] = sheet_idx\n",
    "        df[\"session_id\"] = df[\"session_id\"].astype(\"int32\")\n",
    "\n",
    "        # Convert using FIXED schema\n",
    "        table = pa.Table.from_pandas(\n",
    "            df,\n",
    "            schema=schema,\n",
    "            preserve_index=False\n",
    "        )\n",
    "\n",
    "        if parquet_writer is None:\n",
    "            parquet_writer = pq.ParquetWriter(\n",
    "                output_parquet_path,\n",
    "                schema,\n",
    "                compression=\"snappy\"\n",
    "            )\n",
    "\n",
    "        parquet_writer.write_table(table)\n",
    "        print(f\"  Added {len(df)} samples\")\n",
    "\n",
    "    if parquet_writer:\n",
    "        parquet_writer.close()\n",
    "\n",
    "    print(\"Parquet file written successfully with fixed schema.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b35d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sheet 0: Sheet1\n",
      "  Added 169500 samples\n",
      "Processing sheet 1: Sheet2\n",
      "  Added 30000 samples\n",
      "Processing sheet 2: Sheet3\n",
      "  Added 30000 samples\n",
      "Processing sheet 3: Sheet4\n",
      "  Added 30000 samples\n",
      "Parquet file written successfully with fixed schema.\n"
     ]
    }
   ],
   "source": [
    "RAW_DATA_PATH = Path(\"./Data_raw/\")\n",
    "\n",
    "INPUT_FILE = \"right eye open_1.xlsx\"\n",
    "OUTPUT_FILE = \"eeg_data.parquet\"\n",
    "\n",
    "combine_excel_sheets_to_parquet_eeg(RAW_DATA_PATH / INPUT_FILE, RAW_DATA_PATH / OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf7884",
   "metadata": {},
   "source": [
    "#### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a9e90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILE = \"eeg_data.parquet\"\n",
    "\n",
    "EEG_CHANNELS = [\n",
    "    \"Fp1-A1\", \"Fp2-A2\",\n",
    "    \"P3-A1\", \"P4-A2\", \"Pz-Aav\",\n",
    "    \"O1-A1\", \"O2-A2\",\n",
    "    \"Cz-Aav\"\n",
    "]\n",
    "\n",
    "FS = 125\n",
    "WINDOW_SEC = 10\n",
    "SAMPLES_PER_TRIAL = FS * WINDOW_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e6bf2",
   "metadata": {},
   "source": [
    "#### BAND-PASS FILTERING Theta + Alpha (4–13 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b05a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass_filter(eeg, fs, low=4, high=13, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, eeg, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d414daf",
   "metadata": {},
   "source": [
    "#### TIME–FREQUENCY TRANSFORM (STFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dececf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stft_trial(trial, fs):\n",
    "    ch_tf = []\n",
    "    for ch in trial:\n",
    "        f, t, Z = stft(\n",
    "            ch,\n",
    "            fs=fs,\n",
    "            nperseg=fs,\n",
    "            noverlap=fs // 2\n",
    "        )\n",
    "        mask = (f >= 4) & (f <= 13)\n",
    "        ch_tf.append(np.abs(Z[mask]))\n",
    "    return np.array(ch_tf)  # [C, F, T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcda86bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch, total trials so far: 135\n",
      "Processed batch, total trials so far: 159\n",
      "Processed batch, total trials so far: 183\n",
      "Processed batch, total trials so far: 207\n"
     ]
    }
   ],
   "source": [
    "dataset = ds.dataset(RAW_DATA_PATH / PARQUET_FILE, format=\"parquet\")\n",
    "\n",
    "# Per-session rolling buffers\n",
    "session_buffers = {}  # session_id → [C, N_samples]\n",
    "\n",
    "tf_trials = []  # final output (can also stream-save if huge)\n",
    "\n",
    "for batch in dataset.to_batches(batch_size=200_000):\n",
    "    df = batch.to_pandas()\n",
    "\n",
    "    for sid in df[\"session_id\"].unique():\n",
    "        df_s = df[df[\"session_id\"] == sid]\n",
    "\n",
    "        eeg_chunk = df_s[EEG_CHANNELS].values.T  # [C, chunk_len]\n",
    "\n",
    "        if sid not in session_buffers:\n",
    "            session_buffers[sid] = eeg_chunk\n",
    "        else:\n",
    "            session_buffers[sid] = np.concatenate(\n",
    "                [session_buffers[sid], eeg_chunk], axis=1\n",
    "            )\n",
    "\n",
    "        # While enough samples exist → extract trials\n",
    "        while session_buffers[sid].shape[1] >= SAMPLES_PER_TRIAL:\n",
    "            trial = session_buffers[sid][:, :SAMPLES_PER_TRIAL]\n",
    "            session_buffers[sid] = session_buffers[sid][:, SAMPLES_PER_TRIAL:]\n",
    "\n",
    "            # Filter\n",
    "            trial = bandpass_filter(trial, fs=FS)\n",
    "\n",
    "            # STFT\n",
    "            tf = compute_stft_trial(trial, fs=FS)\n",
    "            tf_trials.append(tf)\n",
    "\n",
    "    print(f\"Processed batch, total trials so far: {len(tf_trials)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b24601",
   "metadata": {},
   "source": [
    "#### CONVERT TO **PyTorch** TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415a28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95b9cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved X_eeg_tf.pt with shape: torch.Size([207, 8, 10, 21])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(np.array(tf_trials), dtype=torch.float32)\n",
    "\n",
    "torch.save(X, \"X_eeg_tf.pt\")\n",
    "print(\"Saved X_eeg_tf.pt with shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2312bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"num_trials\": X.shape[0],\n",
    "    \"channels\": 8,\n",
    "    \"freq_bins\": 10,\n",
    "    \"time_bins\": 21,\n",
    "    \"sampling_rate\": 125,\n",
    "    \"window_sec\": 10,\n",
    "    \"freq_band\": \"4–13 Hz\",\n",
    "    \"preprocessing\": \"parquet_chunked_session_buffered\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59131831",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(metadata, \"eeg_metadata.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
